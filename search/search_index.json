{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#vatrix","title":"\ud83e\udde0 Vatrix","text":"<p>Vatrix is a NLP log processor, rendering natural language descriptions from machine data, and serves several use cases:</p> <ul> <li>streaming NLP &amp; vector embedding</li> <li>batch NDJSON file processing </li> <li>augmented data injection </li> <li>generating training pairs for fine-tuning Sentence Transformers (SBERT)</li> </ul>"},{"location":"#features","title":"\u2728 Features","text":"<ul> <li>CLI-powered NDJSON log processing</li> <li>Modular template system powered by Jinja2</li> <li>SBERT data generation and similarity scoring</li> <li>Supports file mode, stream mode, and CLI flags</li> <li>Exports training pairs to CSV</li> <li>Exports highly similar sentence pairs for SBERT fine-tuning</li> <li>Flexible and colorful logging with log rotation</li> <li>Direct integration with Qdrant vector database (OSAI-Demo Stack)</li> <li>Unit &amp; integration testing</li> </ul>"},{"location":"#installation","title":"\ud83d\udce6 Installation","text":"<p><pre><code>pip install vatrix\n</code></pre> Or install the latest from source: <pre><code>git clone https://github.com/brianbatesactual/vatrix.git\ncd vatrix\nmake setup\n</code></pre></p>"},{"location":"#usage","title":"\ud83d\udee0\ufe0f Usage","text":"<p><pre><code>vatrix --mode file \\\n       --render-mode all \\\n       --input data/input_logs.json \\\n       --output data/processed_logs.csv \\\n       --unmatched data/unmatched_logs.json \\\n       --generate-sbert-data \\\n       --log-level DEBUG \\\n       --log-file logs/vatrix_debug.log\n</code></pre> Makefile Commands <pre><code>make setup         # Create venv and install dependencies\nmake run           # Run log processor on default file\nmake stream        # Start reading NDJSON from stdin\nmake retrain       # Export SBERT sentence pairs\nmake freeze        # Regenerate requirements.txt\nmake clean         # Clean environment and build artifacts\nmake nuke          # Full reset of the project environment\n</code></pre></p>"},{"location":"#example","title":"\ud83e\udde0 Example","text":""},{"location":"#testing","title":"\ud83e\uddea Testing","text":"<p>Run this to test the pipeline <pre><code>make test\n</code></pre></p>"},{"location":"#logs","title":"\ud83d\udcc1 Logs","text":"<p>All logs are saved to the logs/ directory with daily rotation.</p>"},{"location":"#cleanup","title":"\ud83e\uddfc Cleanup","text":"<p>These make commands are the ctrl+z of the project! <pre><code>make clean    # Clean temp data\nmake nuke     # Wipe and rebuild virtualenv\n</code></pre></p>"},{"location":"#license","title":"\ud83d\udcda License","text":"<p>MIT \u00a9 Brian Bates</p> <p>Built with \u2764\ufe0f for log intelligibility and NLP adventures.</p>"},{"location":"example/","title":"Example","text":"<p>[INFO] 2025-04-10 22:15:26,745 - main - \u2705 Logging system initialized</p> <p>[INFO] 2025-04-10 22:15:26,745 - main - Starting vatrix pipeline...</p> <p>[INFO] 2025-04-10 22:15:26,745 - main - Mode: stream | Render mode: random | SBERT Data: False</p> <p>[INFO] 2025-04-10 22:15:26,746 - main - \ud83c\udf0a Stream mode selected. Waiting for NSJSON from standard input.</p> <p>[INFO] 2025-04-10 22:15:26,746 - vatrix.inputs.stream_reader - Listening for NDJSON input (Ctrl+D to end)...</p> <p>{\"EVENT_TYPE\":\"SM20\",\"EVENT_SUBTYPE\":\"\",\"CURRENT_TIMESTAMP\":20250320015236,\"UTCDIFF\":\"110000\",\"UTCSIGN\":\"+\",\"ALGSYSTEM\":\"w16s24id8606\",\"ALGINST\":\"w16s24id8606_ID8_00\",\"ALGDATE\":\"20250320\",\"ALGTIME\":\"125232\",\"ALGCLIENT\":\"800\",\"ALGUSER\":\"DDIC\",\"ALGLTERM\":\"\",\"ALGTCODE\":\"\",\"ALGREPNA\":\"RSBTCRTE\",\"ALGAREA\":\"AU\",\"ALGSUBID\":\"1\",\"TXSUBCLSID\":\"Dialog Logon\",\"TXSEVERITY\":\"Medium\",\"ALGTEXT\":\"Logon successful (type=B, method=A)\",\"ALGFILENO\":\"000001\",\"ALGFILEPOS\":\"0000000000\",\"ALGTASKTYPE\":\"B\",\"ALGTASKNO\":\"021\",\"PARAM1\":\"B\",\"PARAM2\":\"0\",\"PARAM3\":\"A\",\"PARAM4\":\"\",\"IPADDRESS\":\"\",\"MSG\":\"AU1\"}</p> <p>[DEBUG] 2025-04-10 22:15:32,929 - vatrix.inputs.stream_reader - \ud83d\udce5 Received line: {\"EVENT_TYPE\":\"SM20\",\"EVENT_SUBTYPE\":\"\",\"CURRENT_TIMESTAMP\":20250320015236,\"UTCDIFF\":\"110000\",\"UTCSIGN\":\"+\",\"ALGSYSTEM\":\"w16s24id8606\",\"ALGINST\":\"w16s24id8606_ID8_00\",\"ALGDATE\":\"20250320\",\"ALGTIME\":\"125232\",\"ALGCLIENT\":\"800\",\"ALGUSER\":\"DDIC\",\"ALGLTERM\":\"\",\"ALGTCODE\":\"\",\"ALGREPNA\":\"RSBTCRTE\",\"ALGAREA\":\"AU\",\"ALGSUBID\":\"1\",\"TXSUBCLSID\":\"Dialog Logon\",\"TXSEVERITY\":\"Medium\",\"ALGTEXT\":\"Logon successful (type=B, method=A)\",\"ALGFILENO\":\"000001\",\"ALGFILEPOS\":\"0000000000\",\"ALGTASKTYPE\":\"B\",\"ALGTASKNO\":\"021\",\"PARAM1\":\"B\",\"PARAM2\":\"0\",\"PARAM3\":\"A\",\"PARAM4\":\"\",\"IPADDRESS\":\"\",\"MSG\":\"AU1\"}</p> <p>[DEBUG] 2025-04-10 22:15:32,930 - vatrix.pipeline.process_api_ingest - \ud83d\udce5 Ingesting log from API: {'EVENT_TYPE': 'SM20', 'EVENT_SUBTYPE': '', 'CURRENT_TIMESTAMP': 20250320015236, 'UTCDIFF': '110000', 'UTCSIGN': '+', 'ALGSYSTEM': 'w16s24id8606', 'ALGINST': 'w16s24id8606_ID8_00', 'ALGDATE': '20250320', 'ALGTIME': '125232', 'ALGCLIENT': '800', 'ALGUSER': 'DDIC', 'ALGLTERM': '', 'ALGTCODE': '', 'ALGREPNA': 'RSBTCRTE', 'ALGAREA': 'AU', 'ALGSUBID': '1', 'TXSUBCLSID': 'Dialog Logon', 'TXSEVERITY': 'Medium', 'ALGTEXT': 'Logon successful (type=B, method=A)', 'ALGFILENO': '000001', 'ALGFILEPOS': '0000000000', 'ALGTASKTYPE': 'B', 'ALGTASKNO': '021', 'PARAM1': 'B', 'PARAM2': '0', 'PARAM3': 'A', 'PARAM4': '', 'IPADDRESS': '', 'MSG': 'AU1'}</p> <p>[DEBUG] 2025-04-10 22:15:32,931 - vatrix.templates.tmanager - Found 6 variations for 'dialog_logon'.</p> <p>[DEBUG] 2025-04-10 22:15:32,931 - vatrix.templates.tmanager - Selected template: variation_2.j2 for template dialog_logon.</p> <p>[DEBUG] 2025-04-10 22:15:32,936 - vatrix.templates.tmanager - Successfully rendered random template for dialog_logon.</p> <p>[DEBUG] 2025-04-10 22:15:32,936 - vatrix.utils.pathing - \ud83e\udded Resolved path: /Users/brianbates/Library/Application Support/vatrix/stream_output/streamed_logs_20250410_221532.csv</p> <p>[INFO] 2025-04-10 22:15:32,937 - vatrix.outputs.rotating_writer - \ud83d\udd04 Started new stream file: /Users/brianbates/Library/Application Support/vatrix/stream_output/streamed_logs_20250410_221532.csv</p> <p>Batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00,  9.13it/s]</p> <p>\ud83d\udd0e EMBEDDING: 'User DDIC from client 800 accessed the system w16s24id8606 on 20250320 at 125232 using type B and method A.'\\n\u2192 Vector: [-0.05574979  0.05328215 -0.05681858 -0.13123487 -0.06642933]...</p> <p>[DEBUG] 2025-04-10 22:15:33,082 - root - \ud83d\udce6 Sending payload: {   \"project\": \"vatrix-stream\",   \"entries\": [     {       \"id\": \"0f2b0e8c-e476-404b-9964-5a6733c53b79\",       \"vector\": [         -0.055749792605638504,         0.053282152861356735,         -0.056818582117557526,         -0.13123486936092377,         -0.06642933189868927,         -0.020217884331941605,         0.07537119090557098,         0.04252663254737854,         -0.06298499554395676,         -0.03873942792415619,         0.06659043580293655,         0.04859456792473793,         0.012481068260967731,         -0.029508749023079872,         -0.058731965720653534,         0.055047858506441116,         0.013061732053756714,         -0.11084553599357605,         0.04349225386977196,         0.019679220393300056,         0.0025609666481614113,         -0.04141716659069061,         -0.1400139480829239,         -0.010614595375955105,         -0.0307141225785017,         -0.028384745121002197,         0.06260095536708832,         -0.030169636011123657,         0.02876264788210392,         0.042964231222867966,         0.0194547101855278,         0.08966385573148727,         -0.04588107392191887,         -0.03702923282980919,         0.07867889106273651,         -0.018774518743157387,         0.05136509984731674,         0.08196515589952469,         0.02847518026828766,         -0.03808655962347984,         0.02413291484117508,         -0.015671834349632263,         0.04707584157586098,         0.14430223405361176,         0.0317060612142086,         0.04743126779794693,         -0.035621050745248795,         0.027472980320453644,         0.03512992337346077,         -0.012651708908379078,         0.008347867988049984,         0.09371603280305862,         0.028419775888323784,         0.029708942398428917,         -0.020575618371367455,         -0.0676814466714859,         0.05342801287770271,         0.11588184535503387,         0.013595420867204666,         0.06452994793653488,         -0.07569180428981781,         0.0014044976560398936,         0.003474382683634758,         -0.004088456742465496,         -0.019910382106900215,         0.04654195159673691,         0.012003508396446705,         -0.13121657073497772,         0.012175198644399643,         -0.07591515779495239,         -0.03413970395922661,         0.03037836216390133,         -0.009604278020560741,         -0.004774826113134623,         0.015076970681548119,         0.05145895853638649,         -0.06935656815767288,         0.037198133766651154,         0.06941456347703934,         -0.10388674587011337,         0.040525831282138824,         -0.0034599199425429106,         0.024182235822081566,         0.03078940324485302,         0.009626796469092369,         0.052131976932287216,         -0.036903683096170425,         -0.04429227486252785,         0.059061866253614426,         0.03063930757343769,         0.0464736707508564,         -0.03950302302837372,         -0.046324923634529114,         -0.013162979856133461,         -0.023002881556749344,         -0.011466140858829021,         0.04466080293059349,         -0.0441763736307621,         -0.02345661260187626,         0.0709039568901062,         -0.056484781205654144,         0.03440527990460396,         -0.04162890091538429,         0.02633729577064514,         -0.015660643577575684,         -0.044407784938812256,         0.06409617513418198,         0.03712552785873413,         0.04652056470513344,         0.010324815288186073,         0.007041683420538902,         0.009243495762348175,         -0.02172432839870453,         0.027986271306872368,         0.10372769087553024,         -0.09093806147575378,         -0.02153691276907921,         0.04642988368868828,         -0.08894072473049164,         -0.07682041078805923,         -0.018135719001293182,         -0.016564136371016502,         -0.019617395475506783,         -0.05736841633915901,         -0.06189946085214615,         -0.012093446217477322,         0.07716091722249985,         4.619845245655212e-33,         0.025212055072188377,         0.02688095159828663,         -0.004043465480208397,         -0.031058385968208313,         -0.00966139230877161,         0.005169371608644724,         0.08407232910394669,         0.0004042307264171541,         -0.037004001438617706,         0.00030957721173763275,         -0.10442160815000534,         -0.04262347146868706,         0.014993874356150627,         -0.027548128738999367,         0.018230309709906578,         0.02066648192703724,         0.09006601572036743,         0.03111836314201355,         -0.03109193593263626,         0.08888303488492966,         0.08603300154209137,         0.04502689465880394,         0.06866208463907242,         -0.033134907484054565,         0.052211616188287735,         0.07392096519470215,         0.006306312046945095,         0.009050735272467136,         0.09916737675666809,         0.018982641398906708,         0.040449708700180054,         -0.03900047391653061,         -0.035343147814273834,         0.017605844885110855,         -0.02163814567029476,         -0.03494297340512276,         0.059419743716716766,         -0.058543477207422256,         0.019334854558110237,         -0.07727353274822235,         0.015822572633624077,         -0.006794595159590244,         -0.01124620158225298,         -0.028991585597395897,         -0.03022667206823826,         -0.07447987794876099,         -0.03704649955034256,         0.048521388322114944,         0.004923101048916578,         0.060513898730278015,         -0.0894753560423851,         0.0427870973944664,         -0.013570249080657959,         0.009472469799220562,         -0.011069273576140404,         -0.06362350285053253,         0.04112747684121132,         0.033598050475120544,         0.020159868523478508,         0.05040189251303673,         0.08098950237035751,         0.10074939578771591,         -0.0005689592217095196,         -0.07256241887807846,         -0.032808754593133926,         -0.12027330696582794,         -0.023717733100056648,         -0.11057187616825104,         -0.03808126971125603,         -0.022693702951073647,         0.013489841483533382,         0.049223240464925766,         0.07400966435670853,         0.02535758726298809,         -0.09337439388036728,         -0.004485988989472389,         -0.06319986283779144,         0.03854542598128319,         -0.041256580501794815,         0.014880779199302197,         -0.00018976058345288038,         0.0265631303191185,         0.041907716542482376,         0.03867628797888756,         -0.06990937143564224,         0.04382118955254555,         -0.07367391139268875,         0.012083145789802074,         -0.028370792046189308,         0.03887287899851799,         -0.018815331161022186,         0.008600786328315735,         -0.013029438443481922,         0.1017090231180191,         0.017845235764980316,         -5.008635594085868e-33,         -0.11429564654827118,         -0.006864016875624657,         -0.0015994750428944826,         -0.1295185387134552,         -0.007020297925919294,         -0.08059062063694,         -0.04181993007659912,         -0.013302470557391644,         -0.004549083765596151,         0.0690036416053772,         0.07441414147615433,         -0.024909608066082,         -0.0323164239525795,         0.002657625824213028,         0.035845622420310974,         -0.03639434278011322,         -0.05058174952864647,         0.05777941271662712,         -0.04431036487221718,         0.01499983947724104,         -0.012550083920359612,         0.14810167253017426,         0.012011651881039143,         -0.02723454311490059,         -0.0003898989234585315,         0.02172192744910717,         0.019493229687213898,         0.10531260818243027,         -0.015999531373381615,         -0.03820975124835968,         0.0017976685194298625,         0.013965010643005371,         0.03970317915081978,         -0.03082040511071682,         0.037418726831674576,         -0.013302424922585487,         0.04399727284908295,         0.011640997603535652,         -0.024297747761011124,         -0.00932398159056902,         0.03061518445611,         0.04587135091423988,         -0.029013115912675858,         0.020886532962322235,         0.03467167913913727,         0.018648270517587662,         -0.02638840302824974,         -0.013916422612965107,         0.05404161661863327,         -0.004556360188871622,         0.021894847974181175,         -0.038349684327840805,         0.07795613259077072,         0.0789993554353714,         0.027509376406669617,         0.04238751903176308,         0.08607877790927887,         -0.01613251119852066,         0.025520525872707367,         -0.08324573934078217,         0.041738200932741165,         -0.09985525906085968,         -0.022757630795240402,         0.08464539051055908,         0.016882045194506645,         0.027544531971216202,         0.003713753540068865,         -0.047943178564310074,         -0.019614888355135918,         -0.029642751440405846,         -0.049789559096097946,         -0.0225756224244833,         0.01747213862836361,         0.0274796299636364,         0.05695079639554024,         -0.10824975371360779,         -0.09609396010637283,         -0.03894186392426491,         0.007115274202078581,         -0.04507558420300484,         -0.01148183736950159,         0.013423867523670197,         -0.03994345664978027,         -0.03514786809682846,         -0.06859394162893295,         -0.0545562244951725,         0.04366369917988777,         0.0011081203119829297,         -0.052291445434093475,         -0.045702576637268066,         -0.07225844264030457,         -0.03674504533410072,         -0.0798490047454834,         0.011889835819602013,         -0.00014786497922614217,         -2.919775710097383e-08,         -0.019043918699026108,         0.0014727809466421604,         0.04564376175403595,         0.06490062177181244,         -0.009885464794933796,         0.0393158383667469,         -0.06662701815366745,         -0.020246345549821854,         0.015815140679478645,         -0.0372057743370533,         -0.0239003486931324,         -0.0088865477591753,         0.012623298913240433,         -0.03797265514731407,         0.09593214094638824,         -0.05268911272287369,         -0.0011973861837759614,         -0.08139532804489136,         -0.06433430314064026,         -0.05659390985965729,         0.06824424117803574,         -0.08297855406999588,         0.05603663995862007,         -0.03433921933174133,         -0.03799809142947197,         0.013204345479607582,         -0.021515680477023125,         0.09143536537885666,         -0.026613298803567886,         -0.012686643749475479,         -0.04764655977487564,         0.04926016181707382,         -0.03058766759932041,         0.00835398305207491,         -0.05073218420147896,         0.10490252822637558,         -0.006719304248690605,         0.05413663387298584,         0.05142853036522865,         0.02257711999118328,         -0.021061131730675697,         -0.03160938248038292,         -0.06280534714460373,         0.04510219022631645,         0.12348347157239914,         0.015549984760582447,         -0.03188040852546692,         0.01911940984427929,         0.016986656934022903,         -0.018432874232530594,         -0.07355225831270218,         -0.03071683645248413,         0.033738285303115845,         0.07607080787420273,         -0.06642372906208038,         -0.04579846188426018,         -0.07621727883815765,         -0.07383507490158081,         0.009219489991664886,         0.10628370940685272,         -0.019184133037924767,         0.08121610432863235,         -0.021770715713500977,         -0.025693288072943687       ],       \"payload\": {         \"EVENT_TYPE\": \"SM20\",         \"EVENT_SUBTYPE\": \"\",         \"CURRENT_TIMESTAMP\": \"20250320015236\",         \"UTCDIFF\": \"110000\",         \"UTCSIGN\": \"+\",         \"ALGSYSTEM\": \"w16s24id8606\",         \"ALGINST\": \"w16s24id8606_ID8_00\",         \"ALGDATE\": \"20250320\",         \"ALGTIME\": \"125232\",         \"ALGCLIENT\": \"800\",         \"ALGUSER\": \"DDIC\",         \"ALGLTERM\": \"\",         \"ALGTCODE\": \"\",         \"ALGREPNA\": \"RSBTCRTE\",         \"ALGAREA\": \"AU\",         \"ALGSUBID\": \"1\",         \"TXSUBCLSID\": \"Dialog Logon\",         \"TXSEVERITY\": \"Medium\",         \"ALGTEXT\": \"Logon successful (type=B, method=A)\",         \"ALGFILENO\": \"000001\",         \"ALGFILEPOS\": \"0000000000\",         \"ALGTASKTYPE\": \"B\",         \"ALGTASKNO\": \"021\",         \"PARAM1\": \"B\",         \"PARAM2\": \"0\",         \"PARAM3\": \"A\",         \"PARAM4\": \"\",         \"IPADDRESS\": \"\",         \"MSG\": \"AU1\",         \"rendered\": \"User DDIC from client 800 accessed the system w16s24id8606 on 20250320 at 125232 using type B and method A.\",         \"template\": \"dialog_logon\"       },       \"timestamp\": \"2025-04-11T05:15:33.081942\"     }   ] }</p> <p>[DEBUG] 2025-04-10 22:15:33,105 - urllib3.connectionpool - Starting new HTTPS connection (1): 10.0.1.159:443</p> <p>[DEBUG] 2025-04-10 22:15:33,270 - urllib3.connectionpool - https://10.0.1.159:443 \"POST /api/v1/ingest HTTP/1.1\" 200 54</p> <p>[INFO] 2025-04-10 22:15:33,271 - root - \u2705 Successfully shipped 1 vectors to Vatrix-Gateway.</p> <p>[INFO] 2025-04-10 22:15:33,274 - vatrix.pipeline.process_api_ingest - \u2705 Ingest complete: dialog_logon</p>"},{"location":"release_workflow/","title":"Vatrix Feature \u2192 Release Workflow","text":"<p>This checklist outlines the full process for developing a new feature and publishing it to PyPI from a protected <code>main</code> branch using GitHub, <code>make</code>, and <code>twine</code>.</p>"},{"location":"release_workflow/#1-create-feature-branch","title":"\u2705 1. Create Feature Branch","text":"<pre><code>git checkout main\ngit pull origin main\ngit checkout -b feature/&lt;short-description&gt;\n</code></pre>"},{"location":"release_workflow/#2-develop-the-feature","title":"\u270d\ufe0f 2. Develop the Feature","text":"<ul> <li>Write or refactor code under <code>src/vatrix/</code></li> <li>Add or update tests in <code>tests/</code></li> <li>Document the feature in <code>docs/</code> and update <code>mkdocs.yml</code></li> <li>Bump version in <code>pyproject.toml</code> (e.g., <code>version = \"0.2.1\"</code>)</li> </ul>"},{"location":"release_workflow/#3-format-lint-test","title":"\ud83e\uddea 3. Format, Lint, Test","text":"<pre><code>make format     # black + isort\nmake lint       # flake8\nmake check      # pre-commit + lint + format\nmake test       # pytest\n</code></pre>"},{"location":"release_workflow/#4-build-upload-to-testpypi","title":"\ud83d\udce6 4. Build &amp; Upload to TestPyPI","text":"<pre><code>make freeze          # update requirements.txt\nmake test-release    # build and upload to TestPyPI\n</code></pre> <p>Install test release: <pre><code>pip install --index-url https://test.pypi.org/simple vatrix\n</code></pre></p>"},{"location":"release_workflow/#5-commit-changes","title":"\ud83d\udce5 5. Commit Changes","text":"<pre><code>git add .\ngit commit -m \"\u2728 Add &lt;feature&gt;: &lt;summary&gt;\"\ngit push origin feature/&lt;short-description&gt;\n</code></pre>"},{"location":"release_workflow/#6-create-pull-request","title":"\ud83d\ude80 6. Create Pull Request","text":"<ul> <li>Open a PR from <code>feature/branch</code> \u2192 <code>main</code></li> <li>Include:</li> <li>Summary of changes</li> <li>Feature usage or testing notes</li> <li>Optional: \"Closes #issue\"</li> </ul>"},{"location":"release_workflow/#7-merge-pr","title":"\u2705 7. Merge PR","text":"<ul> <li>Approve PR (or request review)</li> <li>Squash and merge via GitHub UI</li> <li>Pull latest <code>main</code>:</li> </ul> <pre><code>git checkout main\ngit pull origin main\n</code></pre>"},{"location":"release_workflow/#8-tag-the-release","title":"\ud83c\udff7\ufe0f 8. Tag the Release","text":"<pre><code>git tag -a vX.Y.Z -m \"Release vX.Y.Z: &lt;highlights&gt;\"\ngit push origin vX.Y.Z\n</code></pre>"},{"location":"release_workflow/#9-publish-to-pypi","title":"\ud83d\udce6 9. Publish to PyPI","text":"<pre><code>make release\n</code></pre> <p>Or manually: <pre><code>python3 -m build\ntwine upload dist/*\n</code></pre></p>"},{"location":"release_workflow/#10-update-github-release-notes","title":"\ud83d\udcd1 10. Update GitHub Release Notes","text":"<ul> <li>Go to GitHub \u2192 Releases</li> <li>Find the new tag</li> <li>Click \"Edit\" to:</li> <li>Add highlights</li> <li>Note features / fixes / breaking changes</li> </ul>"},{"location":"release_workflow/#optional-enhancements","title":"\ud83d\udca1 Optional Enhancements","text":"<ul> <li>Update <code>docs/changelog.md</code></li> <li>Publish docs via <code>mkdocs gh-deploy</code></li> <li>Announce release on README, social, or blog</li> </ul>"},{"location":"release_workflow/#example-versioning-conventions","title":"\u231b Example Versioning Conventions","text":"Type Version Bump Example Patch fix x.y.Z \u2192 x.y.Z+1 <code>0.2.1 \u2192 0.2.2</code> New feat x.y.Z \u2192 x.y+1.0 <code>0.2.1 \u2192 0.3.0</code> Breaking x.y.Z \u2192 x+1.0.0 <code>0.2.1 \u2192 1.0.0</code>"},{"location":"test_plan/","title":"Vatrix Test Plan","text":"<p>Project: Vatrix NLP Processor</p> <p>Version: v0.1.2</p> <p>Environment: Local (staging) &amp; Remote Ubuntu Server running OSAI-Demo Stack</p> <p>Owner: Brian Bates</p> <p>Last Updated: 2025-04-09</p>"},{"location":"test_plan/#1-objective","title":"1. Objective","text":"<p>To validate the functionality, performance, and reliability of the Vatrix NLP Processor and ensure seamless integration with the OSAI Stack handled by Vatrix Gateway. This includes ingestion, buffering, rotation, sentence generation, embedding, and vector database storage.</p>"},{"location":"test_plan/#2-scope","title":"2. Scope","text":"<p>In Scope</p> <ul> <li>REST ingestion API via FastAPI</li> <li>Token-based authentication</li> <li>File buffering and rotation</li> <li>Log-to-text template rendering</li> <li>SBERT sentence pair generation</li> <li>Qdrant embedding storage</li> <li>MongoDB storage layer (optional)</li> <li>TLS/Nginx gateway (optional)</li> </ul> <p>Out of Scope</p> <ul> <li>Frontend visualization layer</li> <li>Analytics dashboard</li> <li>Production monitoring stack</li> </ul>"},{"location":"test_plan/#3-test-categories","title":"3. Test Categories","text":"<p>A. Gateway Writer Validation</p> Test Case Description Expected Result GW-01 Send valid event via REST 200 OK, payload saved GW-02 Send malformed JSON 400 Bad Request GW-03 Send request without token 401 Unauthorized GW-04 Exceed max file size New file rotated GW-05 Exceed max retention period Old file removed GW-06 Simulate disk error Logged error, graceful failure GW-07 High-volume test (e.g. 1k/sec) No drops, buffered correctly <p>B. NLP Processor Validation</p> Test Case Description Expected Result NLP-01 Detect new log file File picked up by processor NLP-02 Match log to template Natural language output NLP-03 Generate SBERT pair CSV contains valid sentence1/2/score NLP-04 Insert vector to Qdrant Embedding indexed and searchable NLP-05 Validate metadata Tags stored correctly in Qdrant NLP-06 Export raw+processed logs CSV written to training directory <p>C. Vector Search &amp; Recall Validation</p> Test Case Description Expected Result VEC-01 Run vector similarity query Top-k results returned VEC-02 Compare sentence and results Similar semantics retrieved VEC-03 Run invalid query 400 or safe fallback <p>D. Security &amp; Deployment</p> Test Case Description Expected Result SEC-01 Use valid token 200 OK SEC-02 Use expired/invalid token 401 Unauthorized SEC-03 Send request via HTTPS Encrypted channel SEC-04 Restart all containers All services come up clean SEC-05 TLS misconfiguration Nginx error logged gracefully <p>E. Observability &amp; Maintenance</p> Test Case Description Expected Result OBS-01 Logging level = INFO Sane, readable logs OBS-02 Rotate logs daily New log file created OBS-03 Send /health check 200 OK OBS-04 Stress test memory/cpu No crash, logs warning if over threshold"},{"location":"test_plan/#4-tooling","title":"4. Tooling","text":"<ul> <li>Test Client: Postman, curl, k6 (for load)</li> <li>Log Inspection: tail -f, less, VSCode</li> <li>DB Validation: qdrant-client</li> <li>Metrics (optional): Prometheus scraping /metrics if added</li> <li>Automation (optional): Makefile task make validate or shell runner</li> </ul>"},{"location":"test_plan/#5-acceptance-criteria","title":"5. Acceptance Criteria","text":"<ul> <li>All functional and integration tests pass.</li> <li>No memory leaks or resource contention during high-volume tests.</li> <li>Log files and embeddings are correctly rotated and retained.</li> <li>REST and vector components are stable under restart and failure simulation.</li> <li>SBERT-generated sentence pairs are semantically valid and ready for fine-tuning.</li> </ul>"},{"location":"test_plan/#6-notes-next-steps","title":"6. Notes &amp; Next Steps","text":"<ul> <li>Review vatrix-processor config for parallel processing mode if scale grows.</li> <li>Consider including sentence-pair QA sampling loop for future fine-tuning UX.</li> <li>CI/CD to run GW + NLP smoke test on push to main.</li> </ul>"},{"location":"features/context_builder/","title":"Context Builder","text":""},{"location":"features/context_builder/#feature","title":"Feature","text":"<p>Transforms raw SAP log fields into a flat Jinja context dictionary.</p>"},{"location":"features/context_builder/#purpose","title":"Purpose","text":"<ul> <li>Support safe template rendering</li> <li>Ensure all expected template variables are available</li> <li>Provide sensible defaults for missing fields</li> </ul>"},{"location":"features/context_builder/#how-it-works","title":"How It Works","text":"<ul> <li>Accepts a raw <code>log_entry</code> dictionary</li> <li>Converts keys to lowercase, formats dates, and inserts <code>na</code> for blanks</li> <li>Returns a fully hydrated dictionary for use in <code>.j2</code> templates</li> </ul>"},{"location":"features/context_builder/#design-choices","title":"Design Choices","text":"<ul> <li>Avoids mutating the original log</li> <li>Provides fallback logic for optional template fields</li> </ul>"},{"location":"features/context_builder/#limitations","title":"Limitations","text":"<ul> <li>Only supports flat log structures</li> <li>No nested key resolution</li> </ul>"},{"location":"features/context_builder/#related-modules","title":"Related Modules","text":""},{"location":"features/dedup/","title":"Deduplication","text":""},{"location":"features/dedup/#feature","title":"Feature","text":"<p>Avoid ingesting duplicate log events during stream processing.</p>"},{"location":"features/dedup/#purpose","title":"Purpose","text":"<p>Improve ingestion efficiency by: - Preventing redundant vector generation - Reducing noise in semantic search - Maintaining integrity of the training dataset</p>"},{"location":"features/dedup/#how-it-works","title":"How It Works","text":"<p><code>UniqueLogCollector</code> caches previously seen log entries and returns <code>False</code> on duplicates.</p> <p>Internally uses in-memory hash tracking.</p>"},{"location":"features/dedup/#design-choices","title":"Design Choices","text":"<ul> <li>Chose in-memory cache for performance</li> <li>Simplicity prioritized over persistence for initial implementation</li> </ul>"},{"location":"features/dedup/#limitations","title":"Limitations","text":"<ul> <li>Not persistent across restarts</li> <li>May not scale to multi-process environments</li> </ul>"},{"location":"features/dedup/#future-work","title":"Future Work","text":"<ul> <li>Use Redis or file-backed caching</li> <li>Add TTL-based cache eviction</li> <li>Support hash strategy override</li> </ul>"},{"location":"features/dedup/#related-modules","title":"Related Modules","text":"<ul> <li><code>vatrix.pipeline.process_api_ingest</code></li> <li><code>vatrix.pipeline.unique_log_collector</code></li> </ul>"},{"location":"features/embedding/","title":"Embedding Pipeline","text":""},{"location":"features/embedding/#feature","title":"Feature","text":"<p>Transform log events into vector embeddings using Sentence-BERT (SBERT) to enable semantic search and ML-based classification.</p>"},{"location":"features/embedding/#purpose","title":"Purpose","text":"<ul> <li>Enable similarity search via Qdrant</li> <li>Support downstream training and fine-tuning</li> <li>Provide natural language representations of rendered log events</li> </ul>"},{"location":"features/embedding/#how-it-works","title":"How It Works","text":"<ol> <li>Log is matched to a template and rendered into a human-readable sentence.</li> <li>The <code>EmbeddingPipeline</code> encodes the sentence using <code>sentence-transformers</code> with the <code>all-MiniLM-L6-v2</code> model.</li> <li>The resulting 384-dimension float vector is included in the Qdrant upsert payload.</li> </ol>"},{"location":"features/embedding/#design-choices","title":"Design Choices","text":"<ul> <li>SBERT chosen for compact model size and balance of speed + quality</li> <li>Sentence embeddings are only generated from rendered templates \u2014 raw logs are excluded from embedding</li> <li>Model is loaded once and cached per process</li> </ul>"},{"location":"features/embedding/#limitations","title":"Limitations","text":"<ul> <li>No batching yet (encode_batch exists but unused)</li> <li>No multi-model support</li> <li>Vector size is fixed at 384 dims</li> </ul>"},{"location":"features/embedding/#future-work","title":"Future Work","text":"<ul> <li>Add support for alternative models (e.g., domain-specific finetuned SBERT)</li> <li>Move to batch inference pipeline for throughput</li> <li>Include LLM embeddings for contrastive search or annotation</li> </ul>"},{"location":"features/embedding/#related-modules","title":"Related Modules","text":""},{"location":"features/file_reader/","title":"File Reader","text":""},{"location":"features/file_reader/#feature","title":"Feature","text":"<p>Load logs from newline-delimited JSON (NDJSON) files for batch processing.</p>"},{"location":"features/file_reader/#purpose","title":"Purpose","text":"<ul> <li>Process historical log archives</li> <li>Enable SBERT dataset creation from saved logs</li> <li>Support <code>--mode file</code> CLI option</li> </ul>"},{"location":"features/file_reader/#how-it-works","title":"How It Works","text":"<ul> <li>Reads from user-specified NDJSON file path</li> <li>Parses each line into a dictionary</li> <li>Yields entries to the processor</li> </ul>"},{"location":"features/file_reader/#design-choices","title":"Design Choices","text":"<ul> <li>Streaming read line-by-line to handle large files</li> <li>Graceful skip on JSON parse errors</li> </ul>"},{"location":"features/file_reader/#limitations","title":"Limitations","text":"<ul> <li>No support for nested folders or compressed files</li> <li>No inline filtering or transformation</li> </ul>"},{"location":"features/file_reader/#related-modules","title":"Related Modules","text":""},{"location":"features/file_writer/","title":"File Writer","text":""},{"location":"features/file_writer/#feature","title":"Feature","text":"<p>Write unmatched or diagnostic logs to a flat JSON file for further analysis.</p>"},{"location":"features/file_writer/#purpose","title":"Purpose","text":"<ul> <li>Capture logs that don't match any template</li> <li>Retain data during pipeline exceptions or mismatches</li> <li>Enable offline inspection or training dataset seeding</li> </ul>"},{"location":"features/file_writer/#how-it-works","title":"How It Works","text":"<ul> <li>Called from <code>process_api_ingest()</code> or <code>process_stream()</code> when <code>template_name == default_template.txt</code></li> <li>Appends JSON entries to a user-defined file</li> </ul>"},{"location":"features/file_writer/#design-choices","title":"Design Choices","text":"<ul> <li>JSON format chosen for structure and compatibility</li> <li>File path is parameterized (or defaults)</li> <li>Writes are immediate and non-batched</li> </ul>"},{"location":"features/file_writer/#limitations","title":"Limitations","text":"<ul> <li>No log rotation or size control</li> <li>No batching or async writes</li> </ul>"},{"location":"features/file_writer/#related-modules","title":"Related Modules","text":""},{"location":"features/loader/","title":"Template Loader","text":""},{"location":"features/loader/#feature","title":"Feature","text":"<p>Load the mapping of log categories to template filenames.</p>"},{"location":"features/loader/#purpose","title":"Purpose","text":"<ul> <li>Establish the template to use for each incoming log type</li> <li>Enable category-specific rendering</li> </ul>"},{"location":"features/loader/#how-it-works","title":"How It Works","text":"<ul> <li>Loads a YAML or JSON mapping from disk</li> <li>Returns a dictionary</li> </ul>"},{"location":"features/loader/#design-choices","title":"Design Choices","text":"<ul> <li>Keeps template config simple and editable</li> <li>Used by both stream and batch modes</li> </ul>"},{"location":"features/loader/#limitations","title":"Limitations","text":"<ul> <li>Must be manually kept in sync with available templates</li> <li>No default fallback logic in loader</li> </ul>"},{"location":"features/loader/#related-modules","title":"Related Modules","text":""},{"location":"features/processor/","title":"Processor (Batch Mode)","text":""},{"location":"features/processor/#feature","title":"Feature","text":"<p>Run batch processing of logs from file, including rendering, scoring, and dataset export.</p>"},{"location":"features/processor/#purpose","title":"Purpose","text":"<ul> <li>Transform a full log archive into:</li> <li>Rendered sentences</li> <li>SBERT sentence pairs</li> <li>Scored similarity data</li> </ul>"},{"location":"features/processor/#how-it-works","title":"How It Works","text":"<ul> <li>Reads NDJSON log input</li> <li>Matches each log to a template</li> <li>Renders sentence</li> <li>Optionally generates SBERT sentence pairs and cosine similarity scores</li> </ul>"},{"location":"features/processor/#design-choices","title":"Design Choices","text":"<ul> <li>Central command layer for <code>--mode file</code></li> <li>Modular: rendering, scoring, and exporting are plug-in calls</li> </ul>"},{"location":"features/processor/#limitations","title":"Limitations","text":"<ul> <li>Requires templates to be pre-loaded</li> <li>No streaming or incremental modes here</li> </ul>"},{"location":"features/processor/#related-modules","title":"Related Modules","text":""},{"location":"features/rotating_writer/","title":"Rotating Stream Writer","text":""},{"location":"features/rotating_writer/#feature","title":"Feature","text":"<p>Automatically rotates local file output for streamed rendered logs.</p>"},{"location":"features/rotating_writer/#purpose","title":"Purpose","text":"<ul> <li>Persist generated sentences from the stream pipeline</li> <li>Avoid unbounded file growth</li> <li>Segment logs by time</li> </ul>"},{"location":"features/rotating_writer/#how-it-works","title":"How It Works","text":"<ul> <li>Rotates files by date (<code>streamed_logs_YYYYMMDD_HHMMSS.csv</code>)</li> <li>Appends each rendered sentence on a new line</li> <li>Automatically creates target directory if missing</li> </ul>"},{"location":"features/rotating_writer/#design-choices","title":"Design Choices","text":"<ul> <li>Named file using timestamp to avoid overwrite</li> <li>Streamed logs written in CSV format for readability and ingestion</li> <li>Writer initialized once per run</li> </ul>"},{"location":"features/rotating_writer/#limitations","title":"Limitations","text":"<ul> <li>No file size-based rotation yet</li> <li>Doesn't delete or clean up old logs</li> </ul>"},{"location":"features/rotating_writer/#related-modules","title":"Related Modules","text":""},{"location":"features/sbert_writer/","title":"SBERT Writer","text":""},{"location":"features/sbert_writer/#feature","title":"Feature","text":"<p>Generate and export sentence pairs for supervised SBERT training.</p>"},{"location":"features/sbert_writer/#purpose","title":"Purpose","text":"<ul> <li>Support fine-tuning of SBERT using log sentence variations</li> <li>Create labeled similarity pairs with associated scores</li> <li>Export structured CSVs for training pipelines</li> </ul>"},{"location":"features/sbert_writer/#how-it-works","title":"How It Works","text":"<ul> <li>Takes a list of <code>(sentence1, sentence2, score)</code> tuples</li> <li>Saves as <code>CSV</code> with headers: <code>sentence1, sentence2, score</code></li> <li>Used during <code>--generate-sbert-data</code> mode</li> </ul>"},{"location":"features/sbert_writer/#design-choices","title":"Design Choices","text":"<ul> <li>CSV chosen for interoperability with HuggingFace Datasets and PyTorch DataLoaders</li> <li>Score format compatible with cosine similarity training objectives</li> </ul>"},{"location":"features/sbert_writer/#limitations","title":"Limitations","text":"<ul> <li>No deduplication</li> <li>Does not automatically score pairs (external similarity module required)</li> </ul>"},{"location":"features/sbert_writer/#related-modules","title":"Related Modules","text":""},{"location":"features/stream_pipeline/","title":"Streaming Ingestion Pipeline","text":""},{"location":"features/stream_pipeline/#feature","title":"Feature","text":"<p>Continuously processes logs from standard input and routes them through the NLP and vectorization pipeline in real time.</p>"},{"location":"features/stream_pipeline/#purpose","title":"Purpose","text":"<ul> <li>Enable real-time ingestion of SAP audit logs</li> <li>Allow users to stream NDJSON input directly into the vector store</li> <li>Serve as the primary mode for production log processing</li> </ul>"},{"location":"features/stream_pipeline/#how-it-works","title":"How It Works","text":"<ol> <li><code>process_stream()</code> listens to <code>stdin</code> via <code>read_from_stdin()</code>.</li> <li>Each log entry is parsed as JSON and passed to <code>process_api_ingest()</code>.</li> <li>Inside <code>process_api_ingest</code>:</li> <li>Deduplication is performed</li> <li>Context is built from raw log</li> <li>Template is matched and rendered</li> <li>Sentence is embedded</li> <li>Vector + metadata is sent to Vatrix-Gateway</li> <li>Sentence is saved via <code>RotatingStreamWriter</code></li> </ol>"},{"location":"features/stream_pipeline/#design-choices","title":"Design Choices","text":"<ul> <li>Designed to run as a continuous service (Ctrl+D to end)</li> <li>Template matching is required before vector generation</li> <li>Each sentence is immediately embedded and upserted</li> <li>Local file output is rotated and persisted for audit/logging</li> </ul>"},{"location":"features/stream_pipeline/#limitations","title":"Limitations","text":"<ul> <li>Stream currently assumes stdin input \u2014 no Kafka or file tailing</li> <li>No retry or backpressure logic in gateway writer</li> <li>Deduplication is in-memory only (not persistent)</li> </ul>"},{"location":"features/stream_pipeline/#future-work","title":"Future Work","text":"<ul> <li>Add support for HTTP streaming ingest</li> <li>Make process_api_ingest mode-agnostic (batch, stream, realtime)</li> <li>Build pipeline stats or event tracing hooks</li> </ul>"},{"location":"features/stream_pipeline/#related-modules","title":"Related Modules","text":"<p>stream_runner.py process_api_ingest.py stream_reader.py</p>"},{"location":"features/stream_reader/","title":"Stream Reader","text":""},{"location":"features/stream_reader/#feature","title":"Feature","text":"<p>Reads NDJSON logs from standard input for live ingestion.</p>"},{"location":"features/stream_reader/#purpose","title":"Purpose","text":"<ul> <li>Accept logs from pasted CLI events, file pipes, or stdin redirect</li> <li>Serve as input layer for <code>make stream</code></li> </ul>"},{"location":"features/stream_reader/#how-it-works","title":"How It Works","text":"<ul> <li>Blocks on <code>input()</code> loop until EOF (Ctrl+D)</li> <li>Parses each line as JSON</li> <li>Yields valid entries to <code>process_stream()</code></li> </ul>"},{"location":"features/stream_reader/#design-choices","title":"Design Choices","text":"<ul> <li>Built for CLI and manual debugging scenarios</li> <li>Fail-fast for malformed lines</li> </ul>"},{"location":"features/stream_reader/#limitations","title":"Limitations","text":"<ul> <li>Only handles <code>stdin</code> \u2014 no sockets, pipes, or Kafka</li> <li>No rate limiting or timeout support</li> </ul>"},{"location":"features/stream_reader/#related-modules","title":"Related Modules","text":""},{"location":"features/stream_runner/","title":"Stream Runner","text":""},{"location":"features/stream_runner/#feature","title":"Feature","text":"<p>Entry point for real-time streaming via CLI. Orchestrates live log ingestion and passes events to <code>process_api_ingest</code>.</p>"},{"location":"features/stream_runner/#purpose","title":"Purpose","text":"<ul> <li>Serve as CLI trigger for <code>make stream</code></li> <li>Wrap <code>stdin</code> reading, rendering, embedding, and gateway forwarding</li> </ul>"},{"location":"features/stream_runner/#how-it-works","title":"How It Works","text":"<ul> <li>Calls <code>read_from_stdin()</code> \u2192 yields log entries</li> <li>For each entry, calls <code>process_api_ingest()</code></li> <li>Handles logging, deduplication, and error recovery</li> </ul>"},{"location":"features/stream_runner/#design-choices","title":"Design Choices","text":"<ul> <li>Small wrapper around stream ingestion logic</li> <li>Abstracts mode-specific wiring away from CLI</li> </ul>"},{"location":"features/stream_runner/#limitations","title":"Limitations","text":"<ul> <li>Assumes logs are NDJSON formatted</li> <li>Does not expose config flags or batch behavior</li> </ul>"},{"location":"features/stream_runner/#related-modules","title":"Related Modules","text":""},{"location":"features/tmanager/","title":"Template Manager","text":""},{"location":"features/tmanager/#feature","title":"Feature","text":"<p>Manages Jinja template rendering, including variation selection and error handling.</p>"},{"location":"features/tmanager/#purpose","title":"Purpose","text":"<ul> <li>Dynamically render logs using category-specific sentence templates</li> <li>Support multiple variations per category for data augmentation</li> </ul>"},{"location":"features/tmanager/#how-it-works","title":"How It Works","text":"<ul> <li>Accepts template name + context</li> <li>Selects a <code>.j2</code> file (random or fixed mode)</li> <li>Renders using <code>Jinja2</code>, returns sentence string</li> </ul>"},{"location":"features/tmanager/#design-choices","title":"Design Choices","text":"<ul> <li>Allows multiple variations per log type (<code>variation_1.j2</code>, <code>variation_2.j2</code>, etc.)</li> <li>Logs failures with context for debugging</li> <li>Random selection helps build robust training sets</li> </ul>"},{"location":"features/tmanager/#limitations","title":"Limitations","text":"<ul> <li>Variation strategy is random \u2014 no weighted or deterministic support</li> <li>Jinja rendering errors are logged, not raised</li> </ul>"},{"location":"features/tmanager/#related-modules","title":"Related Modules","text":""}]}